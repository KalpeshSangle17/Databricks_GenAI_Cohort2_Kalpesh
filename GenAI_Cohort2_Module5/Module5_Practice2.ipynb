{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8d03429-3680-4728-b2c5-e0cd6c715fed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U langgraph langsmith langchain transformers langchain_community torch --upgrade mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "574517ba-ed6b-4452-96ac-bf99b336ba9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "model_name = \"system.ai.llama_v3_2_1b_instruct\"\n",
    "model_version = \"2\"\n",
    "\n",
    "model_uri = f\"models:/{model_name}/{model_version}\"\n",
    "\n",
    "print(f\"Loading model: {model_name}...\")\n",
    "loaded_model = mlflow.pyfunc.load_model(model_uri)\n",
    "print(\"Model successfully loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "968b88bd-540e-473f-b002-540a4a054798",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install guardrails-ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51232f18-bb44-4440-9ecc-e9e197b006bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5afe3e48-8204-4584-b9e2-4186134b56a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from typing import Annotated, TypedDict, List\n",
    "import mlflow\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# Import Guard for validations\n",
    "from guardrails import Guard, OnFailAction\n",
    "\n",
    "# Define the State schema\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[List[HumanMessage], add_messages]\n",
    "\n",
    "# Define the StateGraph\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "689eb143-9ee0-4f54-b2d7-62d0006e6661",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define simple guardrails\n",
    "FORBIDDEN_WORDS = [\"stupid\", \"hate\", \"shut up\"]\n",
    "\n",
    "def contains_forbidden_words(text: str) -> bool:\n",
    "    \"\"\"\n",
    "    Check if the text contains any forbidden words.\n",
    "    \"\"\"\n",
    "    return any(word in text.lower() for word in FORBIDDEN_WORDS)\n",
    "\n",
    "def sanitize_response(response: str) -> str:\n",
    "    \"\"\"\n",
    "    Sanitize the assistant's response if necessary.\n",
    "    \"\"\"\n",
    "    for word in FORBIDDEN_WORDS:\n",
    "        response = response.replace(word, \"[REDACTED]\")\n",
    "    return response\n",
    "\n",
    "# Define the chatbot interaction function\n",
    "def chatbot(state: State) -> State:\n",
    "    \"\"\"\n",
    "    Processes user input, sends it to the MLflow model, and appends \n",
    "    the model's response to the state.\n",
    "    \"\"\"\n",
    "    # Prepare input for the model\n",
    "    input_data = {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": message.content\n",
    "            }\n",
    "            for message in state[\"messages\"]\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Call the MLflow model's predict function\n",
    "    response = loaded_model.predict([input_data])  # The predict method requires a list containing a dictionary\n",
    "    ai_response = str(response)  # Convert the raw response to a string\n",
    "\n",
    "    # Sanitize the AI response\n",
    "    sanitized_response = sanitize_response(ai_response)\n",
    "\n",
    "    # Append the sanitized AI response to the state\n",
    "    return {\n",
    "        \"messages\": state[\"messages\"] + [AIMessage(content=sanitized_response)]\n",
    "    }\n",
    "\n",
    "\n",
    "# Add the chatbot node to the graph\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "# Define the conversation flow\n",
    "graph_builder.add_edge(START, \"chatbot\")  # Start → chatbot\n",
    "graph_builder.add_edge(\"chatbot\", END)  # Chatbot → End\n",
    "\n",
    "# Compile the graph\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "\n",
    "# Function to stream graph updates\n",
    "def stream_graph_updates(user_input: str):\n",
    "    \"\"\"\n",
    "    Streams updates from the graph in response to user input.\n",
    "    Applies a basic guardrail to check for forbidden words.\n",
    "    \"\"\"\n",
    "    # Preprocessing: Check user input for forbidden words\n",
    "    if contains_forbidden_words(user_input):\n",
    "        print(\"Validation failed: Your input contains inappropriate language.\")\n",
    "        return  # Skip processing further\n",
    "    \n",
    "    # Prepare the input state with the user's message\n",
    "    initial_state = {\"messages\": [{\"role\": \"user\", \"content\": user_input}]}\n",
    "\n",
    "    # Stream events from the StateGraph\n",
    "    for event in graph.stream(initial_state):\n",
    "        for value in event.values():\n",
    "            # Print the assistant's response, which is always the last message\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "\n",
    "\n",
    "# Main loop for interaction\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Chatbot is ready! Type 'exit', 'quit', or 'q' to end the session.\")\n",
    "    while True:\n",
    "        try:\n",
    "            # Get user input\n",
    "            user_input = input(\"User: \")\n",
    "            # Exit condition\n",
    "            if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "                print(\"Goodbye!\")\n",
    "                break\n",
    "\n",
    "            # Update the graph and stream responses\n",
    "            stream_graph_updates(user_input)\n",
    "\n",
    "        except Exception as e:\n",
    "            # Fallback behavior for errors\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            print(\"Defaulting to a static response...\")\n",
    "            fallback_input = \"What do you know about LangGraph?\"\n",
    "            print(\"User:\", fallback_input)\n",
    "            stream_graph_updates(fallback_input)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fa7aab32-0704-4bba-b051-8fd47bc71561",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": "HIGH"
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Module5_Practice2",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
