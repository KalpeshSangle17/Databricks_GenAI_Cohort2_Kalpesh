{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c83ddaf2-b955-400f-b12f-a2301d530fe4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install ragas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e298156-c377-4d14-9bf2-6abede6c4a73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8772fd7-2f5b-418e-b302-7e752eef4ce2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#test\n",
    "from ragas import SingleTurnSample\n",
    "from ragas.metrics import BleuScore\n",
    "\n",
    "test_data = {\n",
    "    \"user_input\": \"summarise given text\\nThe company reported an 8% rise in Q3 2024, driven by strong performance in the Asian market. Sales in this region have significantly contributed to the overall growth. Analysts attribute this success to strategic marketing and product localization. The positive trend in the Asian market is expected to continue into the next quarter.\",\n",
    "    \"response\": \"The company experienced an 8% increase in Q3 2024, largely due to effective marketing strategies and product adaptation, with expectations of continued growth in the coming quarter.\",\n",
    "    \"reference\": \"The company reported an 8% growth in Q3 2024, primarily driven by strong sales in the Asian market, attributed to strategic marketing and localized products, with continued growth anticipated in the next quarter.\"\n",
    "}\n",
    "metric = BleuScore()\n",
    "test_data = SingleTurnSample(**test_data)\n",
    "metric.single_turn_score(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5bd6e29d-250a-43d4-9c4a-1994b880fce7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test_data = {\n",
    "    \"user_input\": \"summarise given text\\nVirat Kohli achieved a historic milestone during the India vs Australia ODI series, scoring his 50th century. His exceptional performance helped India secure a decisive victory in the final match. Cricket analysts praised his consistency and unmatched batting prowess, calling him one of the greatest players in the modern era. Kohli's form remains crucial for India's success in upcoming tournaments.\",\n",
    "    \"response\": \"Virat Kohli scored his 50th ODI century during the India-Australia series, aiding India's victory and solidifying his reputation as a modern cricket legend. His performance is key for upcoming tournaments.\",\n",
    "    \"reference\": \"Virat Kohli reached his 50th century in the India-Australia ODI series, earning widespread acclaim for his consistency and batting skill, which were instrumental in India's win and remain vital for future tournaments.\"\n",
    "}\n",
    "\n",
    "metric = BleuScore()\n",
    "test_data = SingleTurnSample(**test_data)\n",
    "metric.single_turn_score(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4bc5c5f9-c327-4ff8-a48f-7836b26f0d77",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Evaluate with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5bc17421-2125-4f1c-945a-e70c900fb477",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U langgraph langsmith langchain transformers langchain_community mlflow torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16195a42-99c6-4362-9116-7b5d2ba766a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "model_name = \"system.ai.llama_v3_2_1b_instruct\"\n",
    "model_version = \"2\"\n",
    "\n",
    "model_uri = f\"models:/{model_name}/{model_version}\"\n",
    "\n",
    "print(f\"Loading model: {model_name}...\")\n",
    "loaded_model = mlflow.pyfunc.load_model(model_uri)\n",
    "print(\"Model successfully loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "793bcd64-eda4-4885-bdd0-f509b2791c9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from langchain.llms.base import LLM\n",
    "from typing import List, Optional, Any\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "\n",
    "class MLflowLangchainLLM(LLM):\n",
    "    model: Any\n",
    "\n",
    "    def __init__(self, model):\n",
    "        super().__init__(model=model)\n",
    "\n",
    "    def _call(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        stop: Optional[List[str]] = None,\n",
    "        *args,  # Accept additional arguments\n",
    "        **kwargs  # Capture extra keyword arguments\n",
    "    ) -> str:\n",
    "        print(f\"[DEBUG] Prompt: {prompt}\")\n",
    "        print(f\"[DEBUG] Stop: {stop}\")\n",
    "        print(f\"[DEBUG] Additional args: {args}\")\n",
    "        print(f\"[DEBUG] Additional kwargs: {kwargs}\")\n",
    "\n",
    "        # Transform the input to match the required schema\n",
    "        formatted_input = {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",       # Role field required by schema\n",
    "                    \"content\": prompt     # Prompt as 'content'\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        print(f\"[DEBUG] Formatted Input: {formatted_input}\")\n",
    "\n",
    "        # Make prediction using MLflow model\n",
    "        try:\n",
    "            response = self.model.predict(formatted_input)\n",
    "            print(f\"[DEBUG] Model Response: {response}\")\n",
    "\n",
    "            # Extract content from response (implementation depends on format)\n",
    "            if isinstance(response, list) and len(response) > 0:\n",
    "                choices = response[0].get('choices', [])\n",
    "                if len(choices) > 0:\n",
    "                    message = choices[0].get('message', {})\n",
    "                    content = message.get('content', None)\n",
    "                    if content:\n",
    "                        return content\n",
    "\n",
    "            # If response format is unexpected\n",
    "            raise ValueError(\"Unable to extract content from model response.\")\n",
    "        except Exception as e:\n",
    "            print(f\"[DEBUG] Error: {e}\")\n",
    "            raise MlflowException(f\"Failed model prediction: {str(e)}\")\n",
    "\n",
    "    @property\n",
    "    def _identifying_params(self) -> dict:\n",
    "        return {\"model_name\": \"mlflow_loaded_llm\"}\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"custom_mlflow_llm\"\n",
    "\n",
    "evaluator_llm = LangchainLLMWrapper(MLflowLangchainLLM(model=loaded_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "737c3114-9606-4e96-ab91-29da5de90c13",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Test input formatted for the model\n",
    "test_input = {\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"Who is the inventor of Telephone?\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Test the model prediction directly\n",
    "response = loaded_model.predict(test_input)\n",
    "print(f\"[DEBUG RAW RESPONSE] {response}\")\n",
    "\n",
    "# Test the MLflowLangchainLLM wrapper\n",
    "evaluator_llm = MLflowLangchainLLM(model=loaded_model)\n",
    "output = evaluator_llm._call(prompt=\"Who is the inventor of Telephone?\")\n",
    "\n",
    "# Print the extracted content\n",
    "print(f\"Extracted Content: {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b131315-5636-47f5-8612-312cb59c2df4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from ragas import SingleTurnSample\n",
    "from ragas.metrics import AspectCritic\n",
    "\n",
    "test_data = {\n",
    "    \"user_input\": \"summarise given text\\nThe company reported an 8% rise in Q3 2024, driven by strong performance in the Asian market. Sales in this region have significantly contributed to the overall growth. Analysts attribute this success to strategic marketing and product localization. The positive trend in the Asian market is expected to continue into the next quarter.\",\n",
    "    \"response\": \"The company experienced an 8% increase in Q3 2024, largely due to effective marketing strategies and product adaptation, with expectations of continued growth in the coming quarter.\",\n",
    "}\n",
    "\n",
    "metric = AspectCritic(name=\"summary_accuracy\",llm=evaluator_llm, definition=\"Verify if the summary is accurate.\")\n",
    "test_data = SingleTurnSample(**test_data)\n",
    "await metric.single_turn_ascore(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9161ffcf-acd0-40ab-b1ef-08192fc89759",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Module_6_HandsOn",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
